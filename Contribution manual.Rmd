---
output:
  md_document:
    variant: markdown_github
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
```



## Section about GitHub/Git/Devtools usage:



## Inserting a new dataset in the package:

Note: for hereon *dataset* stands as an alias for the name of the dataset you are trying to insert on the package, *filetype* as an alias to the subgroups inside each dataset( for PNAD we have the filetypes *pessoas*(*persons*) and  *famÃ­lias*(*households*)) and *period* as an alias to every period available for that dataset and filetype.

Each new dataset depends on four pieces:

- One folder inside `inst/extdata` with the name of the dataset and one subfolder named `dictionaries`
- One file with metadata inside the folder you created with the name `dataset_files_metadata_harmonization.csv`
- One wrapper function defined on the file `R/import_wrapper_functions.R`
- Dictionaries stored inside `dataset/dictionaries` with the name `import_dictionary_dataset_filetype_period.csv`.

The first piece is clear, look at the folders already created for the other datasets if you have any doubt.Now we start with detailed instructions for the next steps.


### 1.  The metadata file

This file stores information about the directory structure, download links, delimiters, and other general information. Using this kind of file allows to separate dataset specific information of the actual code. We suggest that you copy a ready metadata file ( as "PNAD_metadata_files_harmonization.csv" ) and edit it to your needs. The file will be somewhat like this:


| period|format |download_path                                                                                                                                                      |download_mode |missing_symbols |path                                |inputs_folder |data_folder |ft_domicilios                 |ft_pessoas                    |
|------:|:------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------|:---------------|:-----------------------------------|:-------------|:-----------|:-----------------------------|:-----------------------------|
|   2001|fwf    |ftp://ftp.ibge.gov.br/Trabalho_e_Rendimento/Pesquisa_Nacional_por_Amostra_de_Domicilios_anual/microdados/reponderacao_2001_2012/PNAD_reponderado_2001.zip          |source        |NA              |PNAD_reponderado_2001/2001          |Input         |Dados       |INPUT DOM2001.txt&DOM2001.txt |INPUT PES2001.txt&PES2001.txt |
|   2002|fwf    |ftp://ftp.ibge.gov.br/Trabalho_e_Rendimento/Pesquisa_Nacional_por_Amostra_de_Domicilios_anual/microdados/reponderacao_2001_2012/PNAD_reponderado_2002.zip          |source        |NA              |PNAD_reponderado_2002/2002          |Input         |Dados       |INPUT DOM2002.txt&DOM2002.txt |INPUT PES2002.txt&PES2002.txt |
|   2003|fwf    |ftp://ftp.ibge.gov.br/Trabalho_e_Rendimento/Pesquisa_Nacional_por_Amostra_de_Domicilios_anual/microdados/reponderacao_2001_2012/PNAD_reponderado_2003_20150814.zip |source        |NA              |PNAD_reponderado_2003_20150814/2003 |Input         |Dados       |INPUT DOM2003.txt&DOM2003.txt |INPUT PES2003.txt&PES2003.txt |
|   2004|fwf    |ftp://ftp.ibge.gov.br/Trabalho_e_Rendimento/Pesquisa_Nacional_por_Amostra_de_Domicilios_anual/microdados/reponderacao_2001_2012/PNAD_reponderado_2004.zip          |source        |NA              |PNAD_reponderado_2004/2004          |Input         |Dados       |Input_Dom2004.txt&DOM2004.txt |Input_Pes2004.txt&PES2004.txt |
|   2005|fwf    |ftp://ftp.ibge.gov.br/Trabalho_e_Rendimento/Pesquisa_Nacional_por_Amostra_de_Domicilios_anual/microdados/reponderacao_2001_2012/PNAD_reponderado_2005.zip          |source        |NA              |PNAD_reponderado_2005/2005          |Input         |Dados       |Input Dom2005.txt&DOM2005.txt |Input Pes2005.txt&PES2005.txt |
|   2006|fwf    |ftp://ftp.ibge.gov.br/Trabalho_e_Rendimento/Pesquisa_Nacional_por_Amostra_de_Domicilios_anual/microdados/reponderacao_2001_2012/PNAD_reponderado_2006.zip          |source        |NA              |PNAD_reponderado_2006/2006          |Input         |Dados       |Input Dom2006.txt&DOM2006.txt |Input Pes2006.txt&PES2006.txt |
> 



The suggested  order of editions is:

1. Edit/create the period column with the available time periods of the dataset.
2. If you used an template, clean the content of all cells of the table, except for the ones of the period column. If you didn't, create the columns:

- format
- download_path
- download_mode
- missing_symbols
- path
- inputs_folder
- data_folder

3. Create one column for each *file type*(if you used a template from another dataset, also remove the old ones) of the dataset, this columns should be named `ft_filetype`( remember, here *filetype* is just an alias!).

4. Fill the other columns, for each period:

- format: csv if the dataset is a delimited file( even if is stored in other actual format, as .txt). `fwf` if the dataset is  fixed width format file( in this case a dictionary will be needed)
- download_path: The path of the download, can be a direct link from a zipped folder or a path to a ftp folder.
- download_mode: `ftp` for ftp folders and `source` for a direct link
- missing_symbols: comma separated vector with possible missing values of the dataset. NA if none.
- path: The name of the main folder, exactly as downloaded from the source( Ex: PNAD_1401)
- inputs_folder: Inside that folder should be a folder with the dictionaries stored in .txt on .sas format. Keep blank if there is no such folder.
- data_folder: Inside the main folder should be a folder with the data stored. Keep blank if there is no such folder( speacially if the data is stored inside the main folder).
- ft_* : this columns are a little tricky, you may have noted that the content of it is in the format `A&B`. `A` should be the name of the Input dictionary for that filetype in the case of fwf datasets or the delimiter in the case of delimited files. `B` should be the name of the file for that specific dataset, it can also be a regular expression for multiple files( in this case the data of the multiple files will be pooled.)  



Once you have done all that, you can check if is everything working using the functions: `read_metadata` , `get_available_datasets`, `get_available_periods` and `get_available_filetypes`.

### 2. The wrapper function:


### 3. Dictionaries:


